---
output:
  md_document:
    variant: markdown_githu
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Data_load1, echo=F}
aus=read.csv("examiner_aus.csv")
gs=read.csv("examiner_gs.csv")
ids=read.csv("examiner_ids.csv")

#install.packages("gender")
#install.packages("wru")
```

```{r first layer transformation}
library(gender)
library(wru)
library(stringr)
library(dplyr)

#separate last name and first names
ids[c('Last_Name','Names')] <- str_split_fixed(ids$examiner_name, ',', 2)

#remove comma from last name
ids$Last_Name<-gsub(",","",as.character(ids$Last_Name))


ids$Names=trimws(ids$Names)

#sep middle initial and first name
ids[c('name','Middle Initial')] <- str_split_fixed(ids$Names,' ', 2)


#get genders based on first name
Gender<-gender(ids$`name`)
#remove duplicates
#Gender2 <- Gender %>% distinct(name, .keep_all = TRUE)
#package for ethnicty requires surname info
ids$surname=ids$Last_Name
ids=predict_race(ids,surname.only=TRUE)

#join to data
ids <- merge(ids, Gender, by = 'name',all=T)

#drop un needed columns
drop <- c("Names","spacer","proportion_male","proportion_female","year_min","year_max")
ids = ids[,!(names(ids) %in% drop)]
```

```{r dataloader,echo=F}
###2
#run these for first time use
#install.packages("arrow")
#install.packages("mondate")

#required for reading parquet files
library(arrow)
#required for aggregate
library(dplyr)
#requred for quarterly_year field
library(mondate)
library(zoo)


App_data=read_parquet('app_data_sample.parquet')

#easier for data manipulation
#remove when need to run
#App_data=head(App_data,3000)
```


```{r data_manipu,echo=F}
##Transformations
#get the date format cleaned
App_data$Date_time=as.POSIXct(App_data$appl_status_date, format="%d%b%Y %H:%M:%S")
#get the quarter number
App_data$Quarter_Year=as.character(as.yearqtr(App_data$Date_time))
App_data$disposal_type2=App_data$disposal_type

##Data Aggregation
Quarterly_data=aggregate(disposal_type ~ disposal_type2+Quarter_Year+examiner_id,data=App_data, FUN= length)

#creat new frame that will be appeneded to Quartlery data
id_temp=ids

#sort aus data then take uniques so we can get the last art units
aus <- aus[order(-aus$year, -aus$month),] 
aus_distinct=distinct(aus,old_pid, .keep_all = TRUE)

#id_temp contains merged data ready for aggregation
id_temp <- merge(id_temp,aus_distinct,by='old_pid',all=T)
id_temp$gender2<-id_temp$gender

#gender number based on art_number
Gender_number=aggregate(gender2~examiner_art_unit+gender,data=id_temp,FUN=length)
Gender_number=filter(Gender_number, gender == "female")

#people number based on art_number
people_number=aggregate(old_pid~examiner_art_unit,data=id_temp,FUN=length)
people_number$number_people_art_unit=people_number$old_pid
#ethnicities
ethnicity_count=aggregate(cbind(pred.whi,pred.bla,pred.his,pred.asi,pred.oth)~examiner_art_unit,data=id_temp,FUN=sum)
#the "-1" excludes column 1. rounda all others
#verify if needed
#ethnicity_count[,-1] <-round(ethnicity_count[,-1],0)

#merge all count data to id_temp
id_temp <- merge(id_temp,Gender_number,by=cbind('examiner_art_unit','gender'),all=T)
id_temp <- merge(id_temp,people_number,by='examiner_art_unit',all=T)
id_temp <- merge(id_temp,ethnicity_count,by='examiner_art_unit',all=T)

#find if pat_ex have left or not
#assuming if they have left then they will have an end date that is not NA
gs$end_date_format=as.POSIXct(gs$end_date, format="%m/%d/%y")
gs <- gs[rev(order(gs$end_date_format)),] 
gs_distinct_emp=distinct(gs,old_pid, .keep_all = TRUE)
#results indicate that all employees are sill employed by this method
#we may be able to extrapolate the employees based on their average tenue or regular promotion cycles. 

#change in au or not
change_au=unique(aus[c('old_pid','examiner_art_unit')])
change_au=aggregate(examiner_art_unit ~ old_pid,data=change_au, FUN= length)
change_au$art_change=ifelse(change_au$examiner_art_unit>1,"Y","N")



#set the columns the same so that they can be mergened
id_temp$examiner_id=id_temp$patex_id
Quarterly_data <- merge(Quarterly_data, id_temp, by = 'examiner_id',all=T)

#set checkpoint for data
write.csv(Quarterly_data, "Quarterly_data.csv", row.names=FALSE)


Quarterly_data_distinct=Quarterly_data
#change the sorting order
Quarterly_data_distinct <-Quarterly_data_distinct[rev(order(Quarterly_data_distinct$Quarter_Year)),] 
#drop nas

library(tidyr)
Quarterly_data_distinct=Quarterly_data_distinct[!is.na(Quarterly_data_distinct$Quarter_Year),]
#Quarterly_data_distinct=na.omit(Quarterly_data_distinct)
#get uniques
Quarterly_data_distinct=distinct(Quarterly_data_distinct,patex_id, .keep_all = TRUE)
#write csv
write.csv(Quarterly_data_distinct, "Quarterly_data_distincts.csv", row.names=FALSE)

```


```{r}

##Part 3 estimation

#turnover
turnover_numbers=aggregate(resigned2 ~ Year+resigned,data=App_data, FUN= length)

mobility=mean(change_au$examiner_art_unit)


```

```{r, examination of turnover}
new_data=Quarterly_data_distinct
# Delete rows with invalid Quarter_Year values
new_data <- new_data[-(1:10),]

# Create new data frame with excluded 2018-2019 years
# Exclude these years as too little number of employees performed actions in 2018-2019
turnover_data <- new_data[-(1:13),]

# Create a row to indicate that an employee has left
library(stringr)

c=0
for (i in turnover_data$Quarter_Year){
  c=c+1
  if(str_detect(i, '2017') == TRUE){
  turnover_data$left[c] <- 0
  } else {
    turnover_data$left[c] <- 1
  }
}

# Count number of employees that left
emp_left = nrow(turnover_data[turnover_data$left == 1, ])

# Calculate turnover (2000-2016)
install.packages("formattable") 
library("formattable")

av_turnover = percent((emp_left/nrow(turnover_data)))
```

